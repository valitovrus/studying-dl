{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import GPT4All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file.\n",
      "gptj_model_load: loading model from '/mnt/c/projects/ggml-gpt4all-j-v1.3-groovy.bin' - please wait ...\n",
      "gptj_model_load: n_vocab = 50400\n",
      "gptj_model_load: n_ctx   = 2048\n",
      "gptj_model_load: n_embd  = 4096\n",
      "gptj_model_load: n_head  = 16\n",
      "gptj_model_load: n_layer = 28\n",
      "gptj_model_load: n_rot   = 64\n",
      "gptj_model_load: f16     = 2\n",
      "gptj_model_load: ggml ctx size = 5401.45 MB\n",
      "gptj_model_load: kv self size  =  896.00 MB\n",
      "gptj_model_load: ................................... done\n",
      "gptj_model_load: model size =  3609.38 MB / num tensors = 285\n"
     ]
    }
   ],
   "source": [
    "model_path = '/mnt/c/projects/ggml-gpt4all-j-v1.3-groovy.bin'\n",
    "model_n_ctx = 1000\n",
    "callbacks = []\n",
    "llm = GPT4All(model=model_path, n_ctx=model_n_ctx, backend='gptj', callbacks=callbacks, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Colorbuds!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Colorbuds!'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"This is a funny name for a company that makes colorful socks:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb.config import Settings\n",
    "\n",
    "# Define the folder for storing database\n",
    "PERSIST_DIRECTORY = '/home/rus/private-gpt/src/db'\n",
    "\n",
    "# Define the Chroma settings\n",
    "CHROMA_SETTINGS = Settings(\n",
    "        chroma_db_impl='duckdb+parquet',\n",
    "        persist_directory=PERSIST_DIRECTORY,\n",
    "        anonymized_telemetry=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: /home/rus/private-gpt/src/db\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "embeddings_model_name = 'all-MiniLM-L6-v2'\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embeddings_model_name)\n",
    "\n",
    "db = Chroma(persist_directory=PERSIST_DIRECTORY, embedding_function=embeddings, client_settings=CHROMA_SETTINGS)\n",
    "collection = db.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "doc_path = '/home/rus/private-gpt/src/source_documents/kb practical deep learning.md'\n",
    "\n",
    "loader = UnstructuredMarkdownLoader(doc_path)\n",
    "doc = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "chunk_size = 500\n",
    "chunk_overlap = 50\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "\n",
    "fragments = text_splitter.split_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4b5dddb0-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e2ab8-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e2b3a-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e2b94-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e2be4-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e2c34-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e2cac-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e2cfc-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e2d38-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e2d7e-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e2dc4-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e2e00-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e2e3c-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e2e8c-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e2ff4-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e304e-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e309e-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e30f8-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e3166-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e3198-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e31b6-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e31d4-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e31f2-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e3210-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e326a-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e329c-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e32ba-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e32d8-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e32ec-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e330a-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e3328-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e333c-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e335a-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e3378-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e3396-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e33b4-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e33d2-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e33e6-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e3404-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e3422-0f6f-11ee-a7cd-00155d9f2438',\n",
       " '4b5e3440-0f6f-11ee-a7cd-00155d9f2438']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.add_documents(fragments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_source_chunks = 2\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": target_source_chunks})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The most effective method for quickly understanding, implementing, training, evaluating, testing, troubleshooting, debugging an AI system on your own computer involves a combination of online resources and offline materials. Here's how you can do it in four steps with examples from \"Deep Learning,\" step-by-step instructions by example using TensorFlow to teach yourself deep learning:1) Study Online Resources for Deep Learning Basics"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function LLModel._response_callback at 0x7fe47e3d5cf0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rus/mambaforge/lib/python3.10/site-packages/gpt4all/pyllmodel.py\", line 239, in _response_callback\n",
      "    @staticmethod\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples, Tutorials): * [tutorial](https://www.w3schools.com/deeplearning/) - A comprehensive tutorial on the basics of neural networks that covers many common concepts and techniques used in modern machine learning projects such as image recognition using convolutional layers: \"Deep Convolution Neural Networks for Visual Recognition\" by Alexey Bochkovskiy, a great introduction to deep reinforcement-based models.2) Read Books or Take Online Courses (Tutorials): * [Artificial Intelligence Through Deep Learning](https://www.packtpub.com/webdevelopmentbookshop/artificiallyintelligencethroughdeeplearning)- A free online book with detailed tutorials on various topics in deep learning: \"Deep Convolutional Neural Networks for Visual Recognition\" by Alexey Bochkovskiy,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What is the best way to learn deep learning?',\n",
       " 'result': ' The most effective method for quickly understanding, implementing, training, evaluating, testing, troubleshooting, debugging an AI system on your own computer involves a combination of online resources and offline materials. Here\\'s how you can do it in four steps with examples from \"Deep Learning,\" step-by-step instructions by example using TensorFlow to teach yourself deep learning:1) Study Online Resources for Deep Learning BasicsExamples, Tutorials): * [tutorial](https://www.w3schools.com/deeplearning/) - A comprehensive tutorial on the basics of neural networks that covers many common concepts and techniques used in modern machine learning projects such as image recognition using convolutional layers: \"Deep Convolution Neural Networks for Visual Recognition\" by Alexey Bochkovskiy, a great introduction to deep reinforcement-based models.2) Read Books or Take Online Courses (Tutorials): * [Artificial Intelligence Through Deep Learning](https://www.packtpub.com/webdevelopmentbookshop/artificiallyintelligencethroughdeeplearning)- A free online book with detailed tutorials on various topics in deep learning: \"Deep Convolutional Neural Networks for Visual Recognition\" by Alexey Bochkovskiy,',\n",
       " 'source_documents': [Document(page_content='Deep learning = automatic feature extraction. No feature engineering. \\nDifferent tasks can be reformulated as image recognition (generate image from sounds - classify images, generate image from mouse movements, then classify them)\\n\\nGPUs are quick, NN-processing is faster than opening a big image. Therefore, downsize images.', metadata={'source': '/home/rus/private-gpt/src/source_documents/kb practical deep learning.md'}),\n",
       "  Document(page_content='Complex problems require >10 epochs and it needs RandomResizeCrop and data augmentation \\nconfusion matrix - for labeled classification. Helps understand which classes are hard \\nLook into examples with the highest loss. Bad loss: \\n - wrong and confident\\n - correct and inconfident\\n\\nBefore data cleaning - train a model and see where it struggles\\n\\nGPU does not swap memory to disk!', metadata={'source': '/home/rus/private-gpt/src/source_documents/kb practical deep learning.md'})]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"What is the best way to learn deep learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
