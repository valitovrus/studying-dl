{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on https://www.kaggle.com/competitions/word2vec-nlp-tutorial/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp kaggle.json /content\n",
    "!chmod 600 /content/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.13.tar.gz (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /usr/lib/python3/dist-packages (from kaggle) (1.14.0)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from kaggle) (2019.11.28)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.28.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from kaggle) (4.64.1)\n",
      "Requirement already satisfied: python-slugify in /usr/lib/python3/dist-packages (from kaggle) (4.0.0)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->kaggle) (2.8)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.13-py3-none-any.whl size=77717 sha256=3277eda9a26c5478a2d03adf2156264a881b51150cccc67ee3db33b3120e5db6\n",
      "  Stored in directory: /root/.cache/pip/wheels/92/8c/37/96a1971bedc1e74057af1e4852f18de7e8286dea4f12928e6c\n",
      "Successfully built kaggle\n",
      "Installing collected packages: kaggle\n",
      "Successfully installed kaggle-1.5.13\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install kaggle --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## set up custom path to kaggle.json: \n",
    "import os\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = '/content'\n",
    "\n",
    "from pathlib import Path\n",
    "path = Path('word2vec-nlp-tutorial')\n",
    "if not path.exists():\n",
    "    import zipfile,kaggle\n",
    "    kaggle.api.competition_download_cli(str(path))\n",
    "    # for each zip file in the path unzip it\n",
    "    for f in path.glob('*.zip'):\n",
    "        zipfile.ZipFile(f).extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train =  pd.read_csv(path/'labeledTrainData.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>25000</td>\n",
       "      <td>24904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>When i got this movie free from my job, along ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                             review\n",
       "count    25000                                              25000\n",
       "unique   25000                                              24904\n",
       "top     5814_8  When i got this movie free from my job, along ...\n",
       "freq         1                                                  3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci's character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ's music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ's bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i've gave this subject....hmmm well i don't know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci's character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ's music.Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ's bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i've gave this subject....hmmm well i don't know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs1 = BeautifulSoup(train.review[0])\n",
    "bs1.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'With all this stuff going down at the moment with MJ i ve started listening to his music  watching the odd documentary here and there  watched The Wiz and watched Moonwalker again  Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent  Moonwalker is part biography  part feature film which i remember going to see at the cinema when it was originally released  Some of it has subtle messages about MJ s feeling towards the press and also the obvious message of drugs are bad m kay Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring  Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him The actual feature film bit when it finally starts is only on for    minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord  Why he wants MJ dead so bad is beyond me  Because MJ overheard his plans  Nah  Joe Pesci s character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno  maybe he just hates MJ s music Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence  Also  the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene Bottom line  this movie is for people who like MJ on one level or another  which i think is most people   If not  then stay away  It does try and give off a wholesome message and ironically MJ s bestest buddy in this movie is a girl  Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty  Well  with all the attention i ve gave this subject    hmmm well i don t know because people can be different behind closed doors  i know this for a fact  He is either an extremely nice but stupid guy or one of the most sickest liars  I hope he is not the latter '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "letters_only = re.sub(\"[^a-zA-Z]\", \" \", bs1.get_text())\n",
    "letters_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['with', 'all', 'this', 'stuff', 'going'], 437)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = letters_only.lower().split()\n",
    "words[:5],len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['stuff', 'going', 'moment', 'mj', 'started'], 219)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [w for w in words if not w in stopwords.words(\"english\")]\n",
    "words[:5],len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "def clean_review_words(review, remove_stopwords=False):\n",
    "    bs = BeautifulSoup(review)\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", bs.get_text())\n",
    "    words = letters_only.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    return  words\n",
    "\n",
    "\n",
    "def clean_review(review, remove_stopwords=False):\n",
    "    words = clean_review_words(review, remove_stopwords)\n",
    "    return( \" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stuff', 'going', 'moment', 'mj', 'started']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_review_words(train.review[0],True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with all this stuff going down at the moment with mj i ve started listening to his music watching the odd documentary here and there watched the wiz and watched moonwalker again maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent moonwalker is part biography part feature film which i remember going to see at the cinema when it was originally released some of it has subtle messages about mj s feeling towards the press and also the obvious message of drugs are bad m kay visually impressive but of course this is all about michael jackson so unless you remotely like mj in anyway then you are going to hate this and find it boring some may call mj an egotist for consenting to the making of this movie but mj and most of his fans would say that he made it for the fans which if true is really nice of him the actual feature film bit when it finally starts is only on for minutes or so excluding the smooth criminal sequence and joe pesci is convincing as a psychopathic all powerful drug lord why he wants mj dead so bad is beyond me because mj overheard his plans nah joe pesci s character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno maybe he just hates mj s music lots of cool things in this like mj turning into a car and a robot and the whole speed demon sequence also the director must have had the patience of a saint when it came to filming the kiddy bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene bottom line this movie is for people who like mj on one level or another which i think is most people if not then stay away it does try and give off a wholesome message and ironically mj s bestest buddy in this movie is a girl michael jackson is truly one of the most talented people ever to grace this planet but is he guilty well with all the attention i ve gave this subject hmmm well i don t know because people can be different behind closed doors i know this for a fact he is either an extremely nice but stupid guy or one of the most sickest liars i hope he is not the latter'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_review(train.review[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train['clean_review'] = train.review.apply(clean_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci's character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ's music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ's bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i've gave this subject....hmmm well i don't know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\",\n",
       " 'stuff going moment mj started listening music watching odd documentary watched wiz watched moonwalker maybe want get certain insight guy thought really cool eighties maybe make mind whether guilty innocent moonwalker part biography part feature film remember going see cinema originally released subtle messages mj feeling towards press also obvious message drugs bad kay visually impressive course michael jackson unless remotely like mj anyway going hate find boring may call mj egotist consenting making movie mj fans would say made fans true really nice actual feature film bit finally starts minutes excluding smooth criminal sequence joe pesci convincing psychopathic powerful drug lord wants mj dead bad beyond mj overheard plans nah joe pesci character ranted wanted people know supplying drugs etc dunno maybe hates mj music lots cool things like mj turning car robot whole speed demon sequence also director must patience saint came filming kiddy bad sequence usually directors hate working one kid let alone whole bunch performing complex dance scene bottom line movie people like mj one level another think people stay away try give wholesome message ironically mj bestest buddy movie girl michael jackson truly one talented people ever grace planet guilty well attention gave subject hmmm well know people different behind closed doors know fact either extremely nice stupid guy one sickest liars hope latter')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['review'][0], train['clean_review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x5000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1975048 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, \n",
    "                             preprocessor = None, stop_words = None, max_features = 5000)\n",
    "\n",
    "train_data_features = vectorizer.fit_transform(train.clean_review)\n",
    "train_data_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 5000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_features = train_data_features.toarray()\n",
    "train_data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abandoned',\n",
       " 'abc',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'abraham',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absolute',\n",
       " 'absolutely']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "forest = forest.fit( train_data_features, train[\"sentiment\"] )\n",
    "forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25000, 5000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(path/'testData.tsv',sep='\\t')\n",
    "test['clean_review'] = test.review.apply(clean_review)\n",
    "test_data_features = vectorizer.transform(test.clean_review).toarray()\n",
    "test_data_features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_features[3][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12311_10</td>\n",
       "      <td>Naturally in a film who's main themes are of m...</td>\n",
       "      <td>naturally film main themes mortality nostalgia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8348_2</td>\n",
       "      <td>This movie is a disaster within a disaster fil...</td>\n",
       "      <td>movie disaster within disaster film full great...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5828_4</td>\n",
       "      <td>All in all, this is a movie for kids. We saw i...</td>\n",
       "      <td>movie kids saw tonight child loved one point k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7186_2</td>\n",
       "      <td>Afraid of the Dark left me with the impression...</td>\n",
       "      <td>afraid dark left impression several different ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12128_7</td>\n",
       "      <td>A very accurate depiction of small time mob li...</td>\n",
       "      <td>accurate depiction small time mob life filmed ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                             review  \\\n",
       "0  12311_10  Naturally in a film who's main themes are of m...   \n",
       "1    8348_2  This movie is a disaster within a disaster fil...   \n",
       "2    5828_4  All in all, this is a movie for kids. We saw i...   \n",
       "3    7186_2  Afraid of the Dark left me with the impression...   \n",
       "4   12128_7  A very accurate depiction of small time mob li...   \n",
       "\n",
       "                                        clean_review  \n",
       "0  naturally film main themes mortality nostalgia...  \n",
       "1  movie disaster within disaster film full great...  \n",
       "2  movie kids saw tonight child loved one point k...  \n",
       "3  afraid dark left impression several different ...  \n",
       "4  accurate depiction small time mob life filmed ...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['sentiment'] = forest.predict(test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "      <th>clean_review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12311_10</td>\n",
       "      <td>Naturally in a film who's main themes are of m...</td>\n",
       "      <td>naturally film main themes mortality nostalgia...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8348_2</td>\n",
       "      <td>This movie is a disaster within a disaster fil...</td>\n",
       "      <td>movie disaster within disaster film full great...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5828_4</td>\n",
       "      <td>All in all, this is a movie for kids. We saw i...</td>\n",
       "      <td>movie kids saw tonight child loved one point k...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7186_2</td>\n",
       "      <td>Afraid of the Dark left me with the impression...</td>\n",
       "      <td>afraid dark left impression several different ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12128_7</td>\n",
       "      <td>A very accurate depiction of small time mob li...</td>\n",
       "      <td>accurate depiction small time mob life filmed ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                             review  \\\n",
       "0  12311_10  Naturally in a film who's main themes are of m...   \n",
       "1    8348_2  This movie is a disaster within a disaster fil...   \n",
       "2    5828_4  All in all, this is a movie for kids. We saw i...   \n",
       "3    7186_2  Afraid of the Dark left me with the impression...   \n",
       "4   12128_7  A very accurate depiction of small time mob li...   \n",
       "\n",
       "                                        clean_review  sentiment  \n",
       "0  naturally film main themes mortality nostalgia...          1  \n",
       "1  movie disaster within disaster film full great...          0  \n",
       "2  movie kids saw tonight child loved one point k...          1  \n",
       "3  afraid dark left impression several different ...          1  \n",
       "4  accurate depiction small time mob life filmed ...          1  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['id','sentiment']].to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227k/227k [00:00<00:00, 533kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to Bag of Words Meets Bags of Popcorn"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kaggle\n",
    "kaggle.api.competition_submit('submission.csv', 'Random Forest from sample notebook', \n",
    "                              'word2vec-nlp-tutorial')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score for the submission above is: 0.84508\n",
    "\n",
    "lets continue with part 2 https://www.kaggle.com/competitions/word2vec-nlp-tutorial/overview/part-2-word-vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv( path/\"testData.tsv\", delimiter=\"\\t\", quoting=3 )\n",
    "unlabeled_train = pd.read_csv(path/\"unlabeledTrainData.tsv\", delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000, 50000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.review.size, test.review.size, unlabeled_train.review.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_sentences( review, tokenizer, remove_stopwords=False ):\n",
    "    # Function to split a review into parsed sentences. Returns a \n",
    "    # list of sentences, where each sentence is a list of words\n",
    "    #\n",
    "    # 1. Use the NLTK tokenizer to split the paragraph into sentences\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    #\n",
    "    # 2. Loop over each sentence\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append( clean_review_words( raw_sentence, remove_stopwords))\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['with',\n",
       "  'all',\n",
       "  'this',\n",
       "  'stuff',\n",
       "  'going',\n",
       "  'down',\n",
       "  'at',\n",
       "  'the',\n",
       "  'moment',\n",
       "  'with',\n",
       "  'mj',\n",
       "  'i',\n",
       "  've',\n",
       "  'started',\n",
       "  'listening',\n",
       "  'to',\n",
       "  'his',\n",
       "  'music',\n",
       "  'watching',\n",
       "  'the',\n",
       "  'odd',\n",
       "  'documentary',\n",
       "  'here',\n",
       "  'and',\n",
       "  'there',\n",
       "  'watched',\n",
       "  'the',\n",
       "  'wiz',\n",
       "  'and',\n",
       "  'watched',\n",
       "  'moonwalker',\n",
       "  'again'],\n",
       " ['maybe',\n",
       "  'i',\n",
       "  'just',\n",
       "  'want',\n",
       "  'to',\n",
       "  'get',\n",
       "  'a',\n",
       "  'certain',\n",
       "  'insight',\n",
       "  'into',\n",
       "  'this',\n",
       "  'guy',\n",
       "  'who',\n",
       "  'i',\n",
       "  'thought',\n",
       "  'was',\n",
       "  'really',\n",
       "  'cool',\n",
       "  'in',\n",
       "  'the',\n",
       "  'eighties',\n",
       "  'just',\n",
       "  'to',\n",
       "  'maybe',\n",
       "  'make',\n",
       "  'up',\n",
       "  'my',\n",
       "  'mind',\n",
       "  'whether',\n",
       "  'he',\n",
       "  'is',\n",
       "  'guilty',\n",
       "  'or',\n",
       "  'innocent'],\n",
       " ['moonwalker',\n",
       "  'is',\n",
       "  'part',\n",
       "  'biography',\n",
       "  'part',\n",
       "  'feature',\n",
       "  'film',\n",
       "  'which',\n",
       "  'i',\n",
       "  'remember',\n",
       "  'going',\n",
       "  'to',\n",
       "  'see',\n",
       "  'at',\n",
       "  'the',\n",
       "  'cinema',\n",
       "  'when',\n",
       "  'it',\n",
       "  'was',\n",
       "  'originally',\n",
       "  'released']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_to_sentences(train.review[0],tokenizer)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/bs4/__init__.py:404: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sentences = []  # Initialize an empty list of sentences\n",
    "\n",
    "for review in train[\"review\"]:\n",
    "    sentences += review_to_sentences(review, tokenizer)\n",
    "\n",
    "for review in unlabeled_train[\"review\"]:\n",
    "    sentences += review_to_sentences(review, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "794335"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['why', 'he', 'wants', 'mj', 'dead', 'so', 'bad', 'is', 'beyond', 'me']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.23.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.9.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from gensim) (6.3.0)\n",
      "Installing collected packages: gensim\n",
      "Successfully installed gensim-4.3.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 09:48:06,763 : INFO : collecting all words and their counts\n",
      "2023-04-21 09:48:06,765 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-21 09:48:06,828 : INFO : PROGRESS: at sentence #10000, processed 225803 words, keeping 17776 word types\n",
      "2023-04-21 09:48:06,891 : INFO : PROGRESS: at sentence #20000, processed 451842 words, keeping 24946 word types\n",
      "2023-04-21 09:48:06,958 : INFO : PROGRESS: at sentence #30000, processed 671053 words, keeping 30029 word types\n",
      "2023-04-21 09:48:07,030 : INFO : PROGRESS: at sentence #40000, processed 897624 words, keeping 34348 word types\n",
      "2023-04-21 09:48:07,101 : INFO : PROGRESS: at sentence #50000, processed 1120158 words, keeping 37805 word types\n",
      "2023-04-21 09:48:07,186 : INFO : PROGRESS: at sentence #60000, processed 1340913 words, keeping 40769 word types\n",
      "2023-04-21 09:48:07,267 : INFO : PROGRESS: at sentence #70000, processed 1564763 words, keeping 43362 word types\n",
      "2023-04-21 09:48:07,345 : INFO : PROGRESS: at sentence #80000, processed 1784082 words, keeping 45745 word types\n",
      "2023-04-21 09:48:07,423 : INFO : PROGRESS: at sentence #90000, processed 2007590 words, keeping 48167 word types\n",
      "2023-04-21 09:48:07,500 : INFO : PROGRESS: at sentence #100000, processed 2228932 words, keeping 50220 word types\n",
      "2023-04-21 09:48:07,580 : INFO : PROGRESS: at sentence #110000, processed 2449108 words, keeping 52105 word types\n",
      "2023-04-21 09:48:07,657 : INFO : PROGRESS: at sentence #120000, processed 2671053 words, keeping 54142 word types\n",
      "2023-04-21 09:48:07,740 : INFO : PROGRESS: at sentence #130000, processed 2896619 words, keeping 55864 word types\n",
      "2023-04-21 09:48:07,819 : INFO : PROGRESS: at sentence #140000, processed 3113151 words, keeping 57400 word types\n",
      "2023-04-21 09:48:07,898 : INFO : PROGRESS: at sentence #150000, processed 3338976 words, keeping 59085 word types\n",
      "2023-04-21 09:48:07,971 : INFO : PROGRESS: at sentence #160000, processed 3561883 words, keeping 60646 word types\n",
      "2023-04-21 09:48:08,041 : INFO : PROGRESS: at sentence #170000, processed 3785579 words, keeping 62122 word types\n",
      "2023-04-21 09:48:08,119 : INFO : PROGRESS: at sentence #180000, processed 4007541 words, keeping 63534 word types\n",
      "2023-04-21 09:48:08,193 : INFO : PROGRESS: at sentence #190000, processed 4232985 words, keeping 64848 word types\n",
      "2023-04-21 09:48:08,268 : INFO : PROGRESS: at sentence #200000, processed 4456605 words, keeping 66130 word types\n",
      "2023-04-21 09:48:08,342 : INFO : PROGRESS: at sentence #210000, processed 4678976 words, keeping 67439 word types\n",
      "2023-04-21 09:48:08,423 : INFO : PROGRESS: at sentence #220000, processed 4903687 words, keeping 68743 word types\n",
      "2023-04-21 09:48:08,502 : INFO : PROGRESS: at sentence #230000, processed 5125706 words, keeping 70006 word types\n",
      "2023-04-21 09:48:08,584 : INFO : PROGRESS: at sentence #240000, processed 5352561 words, keeping 71213 word types\n",
      "2023-04-21 09:48:08,651 : INFO : PROGRESS: at sentence #250000, processed 5566899 words, keeping 72387 word types\n",
      "2023-04-21 09:48:08,746 : INFO : PROGRESS: at sentence #260000, processed 5787064 words, keeping 73525 word types\n",
      "2023-04-21 09:48:08,830 : INFO : PROGRESS: at sentence #270000, processed 6010188 words, keeping 74846 word types\n",
      "2023-04-21 09:48:08,915 : INFO : PROGRESS: at sentence #280000, processed 6236057 words, keeping 76473 word types\n",
      "2023-04-21 09:48:09,005 : INFO : PROGRESS: at sentence #290000, processed 6459399 words, keeping 77894 word types\n",
      "2023-04-21 09:48:09,084 : INFO : PROGRESS: at sentence #300000, processed 6685698 words, keeping 79236 word types\n",
      "2023-04-21 09:48:09,156 : INFO : PROGRESS: at sentence #310000, processed 6910359 words, keeping 80553 word types\n",
      "2023-04-21 09:48:09,230 : INFO : PROGRESS: at sentence #320000, processed 7135813 words, keeping 81858 word types\n",
      "2023-04-21 09:48:09,308 : INFO : PROGRESS: at sentence #330000, processed 7359632 words, keeping 83103 word types\n",
      "2023-04-21 09:48:09,377 : INFO : PROGRESS: at sentence #340000, processed 7587976 words, keeping 84327 word types\n",
      "2023-04-21 09:48:09,457 : INFO : PROGRESS: at sentence #350000, processed 7811666 words, keeping 85504 word types\n",
      "2023-04-21 09:48:09,534 : INFO : PROGRESS: at sentence #360000, processed 8032213 words, keeping 86674 word types\n",
      "2023-04-21 09:48:09,622 : INFO : PROGRESS: at sentence #370000, processed 8261815 words, keeping 87781 word types\n",
      "2023-04-21 09:48:09,701 : INFO : PROGRESS: at sentence #380000, processed 8486430 words, keeping 88934 word types\n",
      "2023-04-21 09:48:09,800 : INFO : PROGRESS: at sentence #390000, processed 8716601 words, keeping 89949 word types\n",
      "2023-04-21 09:48:09,887 : INFO : PROGRESS: at sentence #400000, processed 8938749 words, keeping 90997 word types\n",
      "2023-04-21 09:48:09,970 : INFO : PROGRESS: at sentence #410000, processed 9160458 words, keeping 91948 word types\n",
      "2023-04-21 09:48:10,043 : INFO : PROGRESS: at sentence #420000, processed 9382746 words, keeping 92995 word types\n",
      "2023-04-21 09:48:10,114 : INFO : PROGRESS: at sentence #430000, processed 9611257 words, keeping 93993 word types\n",
      "2023-04-21 09:48:10,187 : INFO : PROGRESS: at sentence #440000, processed 9836406 words, keeping 94990 word types\n",
      "2023-04-21 09:48:10,258 : INFO : PROGRESS: at sentence #450000, processed 10062008 words, keeping 96113 word types\n",
      "2023-04-21 09:48:10,331 : INFO : PROGRESS: at sentence #460000, processed 10294695 words, keeping 97143 word types\n",
      "2023-04-21 09:48:10,411 : INFO : PROGRESS: at sentence #470000, processed 10522662 words, keeping 98018 word types\n",
      "2023-04-21 09:48:10,486 : INFO : PROGRESS: at sentence #480000, processed 10744661 words, keeping 98945 word types\n",
      "2023-04-21 09:48:10,565 : INFO : PROGRESS: at sentence #490000, processed 10970288 words, keeping 99936 word types\n",
      "2023-04-21 09:48:10,640 : INFO : PROGRESS: at sentence #500000, processed 11192256 words, keeping 100858 word types\n",
      "2023-04-21 09:48:10,718 : INFO : PROGRESS: at sentence #510000, processed 11417274 words, keeping 101752 word types\n",
      "2023-04-21 09:48:10,802 : INFO : PROGRESS: at sentence #520000, processed 11641611 words, keeping 102667 word types\n",
      "2023-04-21 09:48:10,887 : INFO : PROGRESS: at sentence #530000, processed 11866280 words, keeping 103477 word types\n",
      "2023-04-21 09:48:10,967 : INFO : PROGRESS: at sentence #540000, processed 12090486 words, keeping 104343 word types\n",
      "2023-04-21 09:48:11,048 : INFO : PROGRESS: at sentence #550000, processed 12316843 words, keeping 105213 word types\n",
      "2023-04-21 09:48:11,133 : INFO : PROGRESS: at sentence #560000, processed 12539561 words, keeping 106038 word types\n",
      "2023-04-21 09:48:11,216 : INFO : PROGRESS: at sentence #570000, processed 12767140 words, keeping 106857 word types\n",
      "2023-04-21 09:48:11,300 : INFO : PROGRESS: at sentence #580000, processed 12990564 words, keeping 107726 word types\n",
      "2023-04-21 09:48:11,376 : INFO : PROGRESS: at sentence #590000, processed 13215773 words, keeping 108568 word types\n",
      "2023-04-21 09:48:11,452 : INFO : PROGRESS: at sentence #600000, processed 13436983 words, keeping 109274 word types\n",
      "2023-04-21 09:48:11,531 : INFO : PROGRESS: at sentence #610000, processed 13660140 words, keeping 110154 word types\n",
      "2023-04-21 09:48:11,605 : INFO : PROGRESS: at sentence #620000, processed 13885543 words, keeping 110908 word types\n",
      "2023-04-21 09:48:11,682 : INFO : PROGRESS: at sentence #630000, processed 14108834 words, keeping 111680 word types\n",
      "2023-04-21 09:48:11,763 : INFO : PROGRESS: at sentence #640000, processed 14331863 words, keeping 112487 word types\n",
      "2023-04-21 09:48:11,840 : INFO : PROGRESS: at sentence #650000, processed 14557568 words, keeping 113266 word types\n",
      "2023-04-21 09:48:11,909 : INFO : PROGRESS: at sentence #660000, processed 14780199 words, keeping 114020 word types\n",
      "2023-04-21 09:48:11,979 : INFO : PROGRESS: at sentence #670000, processed 15004101 words, keeping 114711 word types\n",
      "2023-04-21 09:48:12,055 : INFO : PROGRESS: at sentence #680000, processed 15229279 words, keeping 115427 word types\n",
      "2023-04-21 09:48:12,129 : INFO : PROGRESS: at sentence #690000, processed 15453670 words, keeping 116228 word types\n",
      "2023-04-21 09:48:12,205 : INFO : PROGRESS: at sentence #700000, processed 15681284 words, keeping 117013 word types\n",
      "2023-04-21 09:48:12,284 : INFO : PROGRESS: at sentence #710000, processed 15904248 words, keeping 117680 word types\n",
      "2023-04-21 09:48:12,353 : INFO : PROGRESS: at sentence #720000, processed 16130167 words, keeping 118336 word types\n",
      "2023-04-21 09:48:12,426 : INFO : PROGRESS: at sentence #730000, processed 16356902 words, keeping 119049 word types\n",
      "2023-04-21 09:48:12,502 : INFO : PROGRESS: at sentence #740000, processed 16578049 words, keeping 119740 word types\n",
      "2023-04-21 09:48:12,579 : INFO : PROGRESS: at sentence #750000, processed 16798325 words, keeping 120398 word types\n",
      "2023-04-21 09:48:12,652 : INFO : PROGRESS: at sentence #760000, processed 17015182 words, keeping 121045 word types\n",
      "2023-04-21 09:48:12,723 : INFO : PROGRESS: at sentence #770000, processed 17244245 words, keeping 121776 word types\n",
      "2023-04-21 09:48:12,803 : INFO : PROGRESS: at sentence #780000, processed 17473908 words, keeping 122467 word types\n",
      "2023-04-21 09:48:12,874 : INFO : PROGRESS: at sentence #790000, processed 17701994 words, keeping 123165 word types\n",
      "2023-04-21 09:48:12,907 : INFO : collected 123505 word types from a corpus of 17798268 raw words and 794335 sentences\n",
      "2023-04-21 09:48:12,908 : INFO : Creating a fresh vocabulary\n",
      "2023-04-21 09:48:13,031 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=40 retains 16490 unique words (13.35% of original 123505, drops 107015)', 'datetime': '2023-04-21T09:48:13.031769', 'gensim': '4.3.1', 'python': '3.9.16 (main, Dec  7 2022, 01:11:51) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-122-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}\n",
      "2023-04-21 09:48:13,033 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=40 leaves 17239122 word corpus (96.86% of original 17798268, drops 559146)', 'datetime': '2023-04-21T09:48:13.033156', 'gensim': '4.3.1', 'python': '3.9.16 (main, Dec  7 2022, 01:11:51) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-122-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}\n",
      "2023-04-21 09:48:13,123 : INFO : deleting the raw counts dictionary of 123505 items\n",
      "2023-04-21 09:48:13,131 : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2023-04-21 09:48:13,132 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 12749795.99803372 word corpus (74.0%% of prior 17239122)', 'datetime': '2023-04-21T09:48:13.132035', 'gensim': '4.3.1', 'python': '3.9.16 (main, Dec  7 2022, 01:11:51) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-122-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}\n",
      "2023-04-21 09:48:13,283 : INFO : estimated required memory for 16490 words and 100 dimensions: 21437000 bytes\n",
      "2023-04-21 09:48:13,284 : INFO : resetting layer weights\n",
      "2023-04-21 09:48:13,298 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-21T09:48:13.298063', 'gensim': '4.3.1', 'python': '3.9.16 (main, Dec  7 2022, 01:11:51) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-122-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}\n",
      "2023-04-21 09:48:13,299 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 16490 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-04-21T09:48:13.299355', 'gensim': '4.3.1', 'python': '3.9.16 (main, Dec  7 2022, 01:11:51) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-122-generic-x86_64-with-glibc2.31', 'event': 'train'}\n",
      "2023-04-21 09:48:14,307 : INFO : EPOCH 0 - PROGRESS: at 8.39% examples, 1064836 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:15,311 : INFO : EPOCH 0 - PROGRESS: at 16.83% examples, 1063921 words/s, in_qsize 8, out_qsize 0\n",
      "2023-04-21 09:48:16,313 : INFO : EPOCH 0 - PROGRESS: at 25.74% examples, 1085273 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:17,316 : INFO : EPOCH 0 - PROGRESS: at 34.94% examples, 1104096 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:18,319 : INFO : EPOCH 0 - PROGRESS: at 43.68% examples, 1107228 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:19,325 : INFO : EPOCH 0 - PROGRESS: at 52.47% examples, 1108752 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:20,330 : INFO : EPOCH 0 - PROGRESS: at 60.96% examples, 1105745 words/s, in_qsize 8, out_qsize 0\n",
      "2023-04-21 09:48:21,331 : INFO : EPOCH 0 - PROGRESS: at 69.75% examples, 1107737 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:22,332 : INFO : EPOCH 0 - PROGRESS: at 78.49% examples, 1108546 words/s, in_qsize 8, out_qsize 0\n",
      "2023-04-21 09:48:23,335 : INFO : EPOCH 0 - PROGRESS: at 87.48% examples, 1111804 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:24,345 : INFO : EPOCH 0 - PROGRESS: at 96.52% examples, 1114389 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:24,736 : INFO : EPOCH 0: training on 17798268 raw words (12751270 effective words) took 11.4s, 1115692 effective words/s\n",
      "2023-04-21 09:48:25,743 : INFO : EPOCH 1 - PROGRESS: at 8.45% examples, 1071740 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:26,752 : INFO : EPOCH 1 - PROGRESS: at 16.66% examples, 1049605 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:27,755 : INFO : EPOCH 1 - PROGRESS: at 25.39% examples, 1068057 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:28,762 : INFO : EPOCH 1 - PROGRESS: at 34.16% examples, 1075957 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:29,771 : INFO : EPOCH 1 - PROGRESS: at 42.35% examples, 1069189 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:30,779 : INFO : EPOCH 1 - PROGRESS: at 49.93% examples, 1051763 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:31,781 : INFO : EPOCH 1 - PROGRESS: at 57.62% examples, 1042043 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:32,792 : INFO : EPOCH 1 - PROGRESS: at 65.40% examples, 1034494 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:33,800 : INFO : EPOCH 1 - PROGRESS: at 73.50% examples, 1033947 words/s, in_qsize 8, out_qsize 0\n",
      "2023-04-21 09:48:34,810 : INFO : EPOCH 1 - PROGRESS: at 81.53% examples, 1031789 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:35,811 : INFO : EPOCH 1 - PROGRESS: at 89.42% examples, 1029589 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:36,823 : INFO : EPOCH 1 - PROGRESS: at 97.07% examples, 1023921 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:37,180 : INFO : EPOCH 1: training on 17798268 raw words (12748194 effective words) took 12.4s, 1024936 effective words/s\n",
      "2023-04-21 09:48:38,200 : INFO : EPOCH 2 - PROGRESS: at 7.65% examples, 964266 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:39,209 : INFO : EPOCH 2 - PROGRESS: at 16.38% examples, 1028317 words/s, in_qsize 8, out_qsize 0\n",
      "2023-04-21 09:48:40,209 : INFO : EPOCH 2 - PROGRESS: at 24.77% examples, 1040519 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:41,214 : INFO : EPOCH 2 - PROGRESS: at 33.03% examples, 1039835 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:42,223 : INFO : EPOCH 2 - PROGRESS: at 41.08% examples, 1035819 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:43,227 : INFO : EPOCH 2 - PROGRESS: at 48.87% examples, 1029273 words/s, in_qsize 8, out_qsize 0\n",
      "2023-04-21 09:48:44,232 : INFO : EPOCH 2 - PROGRESS: at 57.31% examples, 1035794 words/s, in_qsize 8, out_qsize 0\n",
      "2023-04-21 09:48:45,232 : INFO : EPOCH 2 - PROGRESS: at 65.50% examples, 1037635 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:46,242 : INFO : EPOCH 2 - PROGRESS: at 73.79% examples, 1038839 words/s, in_qsize 8, out_qsize 0\n",
      "2023-04-21 09:48:47,254 : INFO : EPOCH 2 - PROGRESS: at 82.27% examples, 1041540 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:48,258 : INFO : EPOCH 2 - PROGRESS: at 90.13% examples, 1038180 words/s, in_qsize 5, out_qsize 2\n",
      "2023-04-21 09:48:49,263 : INFO : EPOCH 2 - PROGRESS: at 97.78% examples, 1032305 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:49,539 : INFO : EPOCH 2: training on 17798268 raw words (12746661 effective words) took 12.3s, 1032364 effective words/s\n",
      "2023-04-21 09:48:50,553 : INFO : EPOCH 3 - PROGRESS: at 7.77% examples, 983631 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-21 09:48:51,559 : INFO : EPOCH 3 - PROGRESS: at 15.69% examples, 990102 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:52,565 : INFO : EPOCH 3 - PROGRESS: at 23.47% examples, 986830 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:53,573 : INFO : EPOCH 3 - PROGRESS: at 31.68% examples, 997155 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:54,577 : INFO : EPOCH 3 - PROGRESS: at 40.17% examples, 1014059 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:55,591 : INFO : EPOCH 3 - PROGRESS: at 48.54% examples, 1021512 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:56,602 : INFO : EPOCH 3 - PROGRESS: at 56.82% examples, 1025129 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:57,612 : INFO : EPOCH 3 - PROGRESS: at 64.84% examples, 1024263 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:58,614 : INFO : EPOCH 3 - PROGRESS: at 72.66% examples, 1021607 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:48:59,614 : INFO : EPOCH 3 - PROGRESS: at 80.47% examples, 1018757 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:49:00,615 : INFO : EPOCH 3 - PROGRESS: at 87.64% examples, 1009428 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:49:01,616 : INFO : EPOCH 3 - PROGRESS: at 95.86% examples, 1012239 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:49:02,147 : INFO : EPOCH 3: training on 17798268 raw words (12748704 effective words) took 12.6s, 1012072 effective words/s\n",
      "2023-04-21 09:49:03,163 : INFO : EPOCH 4 - PROGRESS: at 8.11% examples, 1021507 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-21 09:49:04,170 : INFO : EPOCH 4 - PROGRESS: at 16.30% examples, 1026118 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:49:05,172 : INFO : EPOCH 4 - PROGRESS: at 24.82% examples, 1043080 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:49:06,175 : INFO : EPOCH 4 - PROGRESS: at 33.26% examples, 1047518 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:49:07,187 : INFO : EPOCH 4 - PROGRESS: at 41.47% examples, 1045897 words/s, in_qsize 6, out_qsize 1\n",
      "2023-04-21 09:49:08,194 : INFO : EPOCH 4 - PROGRESS: at 49.70% examples, 1046730 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:49:09,198 : INFO : EPOCH 4 - PROGRESS: at 58.00% examples, 1048675 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:49:10,200 : INFO : EPOCH 4 - PROGRESS: at 66.27% examples, 1049740 words/s, in_qsize 8, out_qsize 0\n",
      "2023-04-21 09:49:11,207 : INFO : EPOCH 4 - PROGRESS: at 75.02% examples, 1056328 words/s, in_qsize 8, out_qsize 0\n",
      "2023-04-21 09:49:12,208 : INFO : EPOCH 4 - PROGRESS: at 83.22% examples, 1054945 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:49:13,223 : INFO : EPOCH 4 - PROGRESS: at 91.43% examples, 1053208 words/s, in_qsize 7, out_qsize 0\n",
      "2023-04-21 09:49:14,219 : INFO : EPOCH 4: training on 17798268 raw words (12749471 effective words) took 12.1s, 1056917 effective words/s\n",
      "2023-04-21 09:49:14,220 : INFO : Word2Vec lifecycle event {'msg': 'training on 88991340 raw words (63744300 effective words) took 60.9s, 1046354 effective words/s', 'datetime': '2023-04-21T09:49:14.220730', 'gensim': '4.3.1', 'python': '3.9.16 (main, Dec  7 2022, 01:11:51) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-122-generic-x86_64-with-glibc2.31', 'event': 'train'}\n",
      "2023-04-21 09:49:14,222 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=16490, vector_size=100, alpha=0.025>', 'datetime': '2023-04-21T09:49:14.222025', 'gensim': '4.3.1', 'python': '3.9.16 (main, Dec  7 2022, 01:11:51) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-122-generic-x86_64-with-glibc2.31', 'event': 'created'}\n",
      "/tmp/ipykernel_32/2057094374.py:12: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  model.init_sims(replace=True)\n",
      "2023-04-21 09:49:14,229 : WARNING : destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n",
      "2023-04-21 09:49:14,232 : INFO : Word2Vec lifecycle event {'fname_or_handle': '100features_40minwords_10context', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-04-21T09:49:14.232586', 'gensim': '4.3.1', 'python': '3.9.16 (main, Dec  7 2022, 01:11:51) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-122-generic-x86_64-with-glibc2.31', 'event': 'saving'}\n",
      "2023-04-21 09:49:14,233 : INFO : not storing attribute cum_table\n",
      "2023-04-21 09:49:14,269 : INFO : saved 100features_40minwords_10context\n"
     ]
    }
   ],
   "source": [
    "num_features = 100    # Word vector dimensionality                      \n",
    "min_word_count = 40   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "from gensim.models import word2vec\n",
    "\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers, min_count = min_word_count, \n",
    "                          window = context, sample = downsampling)\n",
    "\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "model_name = \"100features_40minwords_10context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kitchen'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.doesnt_match(\"man woman child kitchen\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'berlin'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.doesnt_match(\"france england germany berlin\".split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paris'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.doesnt_match(\"paris berlin london austria\".split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.730812132358551),\n",
       " ('lad', 0.706100583076477),\n",
       " ('boy', 0.6874200105667114),\n",
       " ('soldier', 0.6723482608795166),\n",
       " ('lady', 0.6720548868179321),\n",
       " ('guy', 0.6528904438018799),\n",
       " ('person', 0.634056806564331),\n",
       " ('monk', 0.6250230073928833),\n",
       " ('chap', 0.6122916340827942),\n",
       " ('farmer', 0.6015139818191528)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(\"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = wv[\"queen\"] - wv[\"man\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('complement', 0.0),\n",
       " ('fares', 0.0),\n",
       " ('thirsty', 0.0),\n",
       " ('lipstick', 0.0),\n",
       " ('humane', 0.0),\n",
       " ('highlighted', 0.0),\n",
       " ('canadians', 0.0),\n",
       " ('defence', 0.0),\n",
       " ('refund', 0.0),\n",
       " ('goo', 0.0)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets a word that is similar to the vector x\n",
    "wv.similar_by_vector(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = wv[\"man\"] + wv[\"royal\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('royal', 0.7769883871078491),\n",
       " ('queen', 0.7769883871078491),\n",
       " ('man', 0.7769883871078491),\n",
       " ('soldier', 0.7629314661026001),\n",
       " ('lad', 0.7098776698112488),\n",
       " ('farmer', 0.7046628594398499),\n",
       " ('ruler', 0.6472869515419006),\n",
       " ('dictator', 0.6392303705215454),\n",
       " ('squire', 0.6382250785827637),\n",
       " ('priest', 0.6337595582008362)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similar_by_vector(x)# doesn't seem to work   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method KeyedVectors.distance of <gensim.models.keyedvectors.KeyedVectors object at 0x7f89a0a9a160>>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.distance()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transformers as per https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'sentiment', 'review'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset,DatasetDict\n",
    "ds = Dataset.from_pandas(train)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57b077508bf4fab99987d0515001414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9815de0fe0841f592c58dab25dc72de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c898e63e0e7c490888e8b5a136224193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spm.model:   0%|          | 0.00/2.35M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/usr/local/lib/python3.9/dist-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_nm = 'microsoft/deberta-v3-small'\n",
    "from transformers import AutoModelForSequenceClassification,AutoTokenizer\n",
    "tokz = AutoTokenizer.from_pretrained(model_nm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁With',\n",
       " '▁all',\n",
       " '▁this',\n",
       " '▁stuff',\n",
       " '▁going',\n",
       " '▁down',\n",
       " '▁at',\n",
       " '▁the',\n",
       " '▁moment',\n",
       " '▁with']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokz.tokenize(train.review[0])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok_func(x): return tokz(x[\"review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e046b16692f4d2184d2236848fdf854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tok_ds = ds.map(tok_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'sentiment', 'review', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'sentiment', 'review', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 18750\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'sentiment', 'review', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 6250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dds = tok_ds.train_test_split(0.25, seed=42)\n",
    "dds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9421, 9329)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dds['train']['sentiment'].count(1), dds['train']['sentiment'].count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3079, 3171)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dds['test']['sentiment'].count(1), dds['test']['sentiment'].count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'labels', 'review', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 18750\n",
       "})"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dds['train'].rename_column('sentiment','labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'labels', 'review', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 6250\n",
       "})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dds['test'].rename_column('sentiment','labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b6d515b1754d0e9857369de7fc8baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_ds = Dataset.from_pandas(test).map(tok_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'review', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments,Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128\n",
    "epochs = 4\n",
    "lr = 8e-5\n",
    "\n",
    "args = TrainingArguments('hf-output', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n",
    "    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n",
    "    num_train_epochs=epochs, weight_decay=0.01, report_to='none')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(x,y): return np.corrcoef(x,y)[0][1]\n",
    "def corr_d(eval_pred): return {'pearson': corr(*eval_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24723a4b9c504d8ab42165451662eddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/273M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-small were not used when initializing DebertaV2ForSequenceClassification: ['lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\n",
    "trainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n",
    "                  tokenizer=tokz, compute_metrics=corr_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: id, sentiment, review. If id, sentiment, review are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 18750\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 588\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 6.28 GiB (GPU 0; 15.90 GiB total capacity; 4.79 GiB already allocated; 5.81 GiB free; 9.39 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\projects\\studying-dl\\nlp-reviews-tutorial.ipynb Cell 73\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/c%3A/projects/studying-dl/nlp-reviews-tutorial.ipynb#Y143sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py:1498\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1493\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1495\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1496\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1497\u001b[0m )\n\u001b[0;32m-> 1498\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1499\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1500\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1501\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1502\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1503\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py:1740\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1738\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1739\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1740\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1743\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1744\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1745\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1746\u001b[0m ):\n\u001b[1;32m   1747\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1748\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py:2470\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2467\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   2469\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2470\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[1;32m   2472\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   2473\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py:2502\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2500\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2501\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2502\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   2503\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2504\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2505\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:1282\u001b[0m, in \u001b[0;36mDebertaV2ForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1274\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1275\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1276\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1277\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1278\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1282\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeberta(\n\u001b[1;32m   1283\u001b[0m     input_ids,\n\u001b[1;32m   1284\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1285\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1286\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1287\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1288\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1289\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1290\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1291\u001b[0m )\n\u001b[1;32m   1293\u001b[0m encoder_layer \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1294\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(encoder_layer)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:1053\u001b[0m, in \u001b[0;36mDebertaV2Model.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1043\u001b[0m     token_type_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(input_shape, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m   1045\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m   1046\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1047\u001b[0m     token_type_ids\u001b[39m=\u001b[39mtoken_type_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1050\u001b[0m     inputs_embeds\u001b[39m=\u001b[39minputs_embeds,\n\u001b[1;32m   1051\u001b[0m )\n\u001b[0;32m-> 1053\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1054\u001b[0m     embedding_output,\n\u001b[1;32m   1055\u001b[0m     attention_mask,\n\u001b[1;32m   1056\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1057\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1058\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1059\u001b[0m )\n\u001b[1;32m   1060\u001b[0m encoded_layers \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m1\u001b[39m]\n\u001b[1;32m   1062\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mz_steps \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:502\u001b[0m, in \u001b[0;36mDebertaV2Encoder.forward\u001b[0;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[1;32m    493\u001b[0m     output_states \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    494\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    495\u001b[0m         next_kv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    499\u001b[0m         rel_embeddings,\n\u001b[1;32m    500\u001b[0m     )\n\u001b[1;32m    501\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 502\u001b[0m     output_states \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    503\u001b[0m         next_kv,\n\u001b[1;32m    504\u001b[0m         attention_mask,\n\u001b[1;32m    505\u001b[0m         query_states\u001b[39m=\u001b[39;49mquery_states,\n\u001b[1;32m    506\u001b[0m         relative_pos\u001b[39m=\u001b[39;49mrelative_pos,\n\u001b[1;32m    507\u001b[0m         rel_embeddings\u001b[39m=\u001b[39;49mrel_embeddings,\n\u001b[1;32m    508\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    509\u001b[0m     )\n\u001b[1;32m    511\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n\u001b[1;32m    512\u001b[0m     output_states, att_m \u001b[39m=\u001b[39m output_states\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:346\u001b[0m, in \u001b[0;36mDebertaV2Layer.forward\u001b[0;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    338\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    339\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    344\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    345\u001b[0m ):\n\u001b[0;32m--> 346\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    347\u001b[0m         hidden_states,\n\u001b[1;32m    348\u001b[0m         attention_mask,\n\u001b[1;32m    349\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    350\u001b[0m         query_states\u001b[39m=\u001b[39;49mquery_states,\n\u001b[1;32m    351\u001b[0m         relative_pos\u001b[39m=\u001b[39;49mrelative_pos,\n\u001b[1;32m    352\u001b[0m         rel_embeddings\u001b[39m=\u001b[39;49mrel_embeddings,\n\u001b[1;32m    353\u001b[0m     )\n\u001b[1;32m    354\u001b[0m     \u001b[39mif\u001b[39;00m output_attentions:\n\u001b[1;32m    355\u001b[0m         attention_output, att_matrix \u001b[39m=\u001b[39m attention_output\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:277\u001b[0m, in \u001b[0;36mDebertaV2Attention.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    269\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    270\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m     rel_embeddings\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    276\u001b[0m ):\n\u001b[0;32m--> 277\u001b[0m     self_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[1;32m    278\u001b[0m         hidden_states,\n\u001b[1;32m    279\u001b[0m         attention_mask,\n\u001b[1;32m    280\u001b[0m         output_attentions,\n\u001b[1;32m    281\u001b[0m         query_states\u001b[39m=\u001b[39;49mquery_states,\n\u001b[1;32m    282\u001b[0m         relative_pos\u001b[39m=\u001b[39;49mrelative_pos,\n\u001b[1;32m    283\u001b[0m         rel_embeddings\u001b[39m=\u001b[39;49mrel_embeddings,\n\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m     \u001b[39mif\u001b[39;00m output_attentions:\n\u001b[1;32m    286\u001b[0m         self_output, att_matrix \u001b[39m=\u001b[39m self_output\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:699\u001b[0m, in \u001b[0;36mDisentangledSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    697\u001b[0m     scale_factor \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    698\u001b[0m scale \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39msqrt(query_layer\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m scale_factor)\n\u001b[0;32m--> 699\u001b[0m attention_scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mbmm(query_layer, key_layer\u001b[39m.\u001b[39;49mtranspose(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m)) \u001b[39m/\u001b[39m scale\n\u001b[1;32m    700\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelative_attention:\n\u001b[1;32m    701\u001b[0m     rel_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_dropout(rel_embeddings)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 6.28 GiB (GPU 0; 15.90 GiB total capacity; 4.79 GiB already allocated; 5.81 GiB free; 9.39 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3291"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## clears up cuda memory\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
